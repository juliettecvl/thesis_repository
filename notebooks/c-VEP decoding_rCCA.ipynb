{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04acb3f3",
   "metadata": {},
   "source": [
    "## Decoding pipeline c-VEP\n",
    "Below is the decoding pipeline used for c-VEP. The following pre-processing has already been done:\n",
    "1. Bandpass filtering (1-40 Hz).\n",
    "2. Epoching around stimulus events. The trials have a duration of 20 seconds, epoching is done 5 seconds before stimulus onset until 25 seconds after stimulus onset.\n",
    "3. Resampling to 120 Hz. This reduces data size and speeds up processing without losing relevant frequency information\n",
    "\n",
    "### Results\n",
    "Only using rCCA and no ICA leads to an average of 99% for the overt paradigm and 60.5% for covert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb0de3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_40452/1339629909.py:11: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPpdia\tovert: Samples (N): 20, Features (D): 148800, Ratio: 0.000134\n",
      "Shape of y: (20,)\n",
      "\n",
      "Shape of X_trn: (15, 62, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 62, 2400)\n",
      "\n",
      "Shape of X_trn: (15, 62, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 62, 2400)\n",
      "\n",
      "Shape of X_trn: (15, 62, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 62, 2400)\n",
      "\n",
      "Shape of X_trn: (15, 62, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 62, 2400)\n",
      "1.000\tcovert: Samples (N): 80, Features (D): 148800, Ratio: 0.000538\n",
      "Shape of y: (80,)\n",
      "\n",
      "Shape of X_trn: (60, 62, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 62, 2400)\n",
      "\n",
      "Shape of X_trn: (60, 62, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 62, 2400)\n",
      "\n",
      "Shape of X_trn: (60, 62, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 62, 2400)\n",
      "\n",
      "Shape of X_trn: (60, 62, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 62, 2400)\n",
      "0.588\t\n",
      "VPpdib\tovert: Samples (N): 20, Features (D): 146400, Ratio: 0.000137\n",
      "Shape of y: (20,)\n",
      "\n",
      "Shape of X_trn: (15, 61, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 61, 2400)\n",
      "\n",
      "Shape of X_trn: (15, 61, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 61, 2400)\n",
      "\n",
      "Shape of X_trn: (15, 61, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 61, 2400)\n",
      "\n",
      "Shape of X_trn: (15, 61, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 61, 2400)\n",
      "1.000\tcovert: Samples (N): 80, Features (D): 146400, Ratio: 0.000546\n",
      "Shape of y: (80,)\n",
      "\n",
      "Shape of X_trn: (60, 61, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 61, 2400)\n",
      "\n",
      "Shape of X_trn: (60, 61, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 61, 2400)\n",
      "\n",
      "Shape of X_trn: (60, 61, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 61, 2400)\n",
      "\n",
      "Shape of X_trn: (60, 61, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 61, 2400)\n",
      "0.625\t\n",
      "VPpdic\tovert: Samples (N): 20, Features (D): 151200, Ratio: 0.000132\n",
      "Shape of y: (20,)\n",
      "\n",
      "Shape of X_trn: (15, 63, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 63, 2400)\n",
      "\n",
      "Shape of X_trn: (15, 63, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 63, 2400)\n",
      "\n",
      "Shape of X_trn: (15, 63, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 63, 2400)\n",
      "\n",
      "Shape of X_trn: (15, 63, 2400)\n",
      "Shape of y_trn: (15,)\n",
      "shape of X_tst: (5, 63, 2400)\n",
      "1.000\tcovert: Samples (N): 80, Features (D): 151200, Ratio: 0.000529\n",
      "Shape of y: (80,)\n",
      "\n",
      "Shape of X_trn: (60, 63, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 63, 2400)\n",
      "\n",
      "Shape of X_trn: (60, 63, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 63, 2400)\n",
      "\n",
      "Shape of X_trn: (60, 63, 2400)\n",
      "Shape of y_trn: (60,)\n",
      "shape of X_tst: (20, 63, 2400)\n",
      "\n",
      "Shape of X_trn: (60, 63, 2400)\n",
      "Shape of y_trn: (60,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_trn:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_trn\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of y_trn:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_trn\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 73\u001b[0m \u001b[43mrcca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Apply classifier\u001b[39;00m\n\u001b[1;32m     76\u001b[0m yh_tst \u001b[38;5;241m=\u001b[39m rcca\u001b[38;5;241m.\u001b[39mpredict(X_tst)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pyntbci/classifiers.py:846\u001b[0m, in \u001b[0;36mrCCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_class \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_classes):\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cca\u001b[38;5;241m.\u001b[39mappend(CCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components, gamma_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_x, gamma_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_m,\n\u001b[1;32m    845\u001b[0m                          estimator_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_estimator_x, estimator_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_estimator_m))\n\u001b[0;32m--> 846\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cca\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi_class\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi_class\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi_class\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_[:, :, i_class] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cca[i_class]\u001b[38;5;241m.\u001b[39mw_x_\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr_[:, :, i_class] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cca[i_class]\u001b[38;5;241m.\u001b[39mw_y_\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pyntbci/transformers.py:203\u001b[0m, in \u001b[0;36mCCA.fit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X3D_Y1D(X, Y)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X3D_Y3D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X2D_Y2D(X, Y)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pyntbci/transformers.py:154\u001b[0m, in \u001b[0;36mCCA._fit_X3D_Y3D\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    151\u001b[0m Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape((n_samples \u001b[38;5;241m*\u001b[39m n_trials, n_features_y))\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# CCA\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X2D_Y2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pyntbci/transformers.py:73\u001b[0m, in \u001b[0;36mCCA._fit_X2D_Y2D\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     70\u001b[0m Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Compute covariances\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_xy_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg_xy_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_xy_ \u001b[38;5;241m=\u001b[39m covariance(Z, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_xy_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg_xy_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_xy_,\n\u001b[1;32m     75\u001b[0m                                                     estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, running\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator_x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Jordy Thielen (jordy.thielen@donders.ru.nl)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import mne\n",
    "import pandas as pd\n",
    "import pyntbci\n",
    "\n",
    "data_dir = '/Users/juliette/Desktop/thesis/preprocessing/c-VEP_preprocessing'\n",
    "save_dir = '/Users/juliette/Desktop/thesis/results/c-VEP'\n",
    "subjects = [\n",
    "    \"VPpdia\", \"VPpdib\", \"VPpdic\", \"VPpdid\", \"VPpdie\", \"VPpdif\", \"VPpdig\", \"VPpdih\", \"VPpdii\", \"VPpdij\", \"VPpdik\",\n",
    "    \"VPpdil\", \"VPpdim\", \"VPpdin\", \"VPpdio\", \"VPpdip\", \"VPpdiq\", \"VPpdir\", \"VPpdis\", \"VPpdit\", \"VPpdiu\", \"VPpdiv\",\n",
    "    \"VPpdiw\", \"VPpdix\", \"VPpdiy\", \"VPpdiz\", \"VPpdiza\", \"VPpdizb\", \"VPpdizc\"\n",
    "]\n",
    "\n",
    "tasks = [\"overt\", \"covert\"]\n",
    "\n",
    "event = \"dur\"\n",
    "onset_event = True\n",
    "encoding_length = 0.3\n",
    "ensemble = True\n",
    "n_folds = 4\n",
    "\n",
    "# Define performance arrays\n",
    "accuracy = np.zeros((len(subjects), len(tasks), n_folds))\n",
    "accuracy_se = np.zeros((len(subjects), len(tasks)))\n",
    "accuracy_mean = np.zeros((len(subjects), len(tasks)))\n",
    "\n",
    "# Loop participants\n",
    "for i_subject, subject in enumerate(subjects):\n",
    "    print(f\"{subject}\", end=\"\\t\")\n",
    "\n",
    "    # Loop tasks\n",
    "    for i_task, task in enumerate(tasks):\n",
    "        print(f\"{task}: \", end=\"\")\n",
    "\n",
    "        # Load data\n",
    "        fn = os.path.join(data_dir, f\"sub-{subject}_task-{task}.npz\")\n",
    "        tmp = np.load(fn)\n",
    "        fs = int(tmp[\"fs\"])\n",
    "        X = tmp[\"X\"]\n",
    "        N = X.shape[0]  # number of trials\n",
    "        D = X.shape[1] * X.shape[2]  # channels × time points\n",
    "        ratio = N / D\n",
    "        print(f\"Samples (N): {N}, Features (D): {D}, Ratio: {ratio:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        y = tmp[\"y\"]\n",
    "        print(\"Shape of y:\", y.shape)\n",
    "        V = tmp[\"V\"]\n",
    "\n",
    "        # Cross-validation\n",
    "        folds = np.repeat(np.arange(n_folds), int(X.shape[0] / n_folds))\n",
    "        for i_fold in range(n_folds):\n",
    "            # Split data to train and test set\n",
    "            X_trn, y_trn = X[folds != i_fold, :, :], y[folds != i_fold]\n",
    "            X_tst, y_tst = X[folds == i_fold, :, :], y[folds == i_fold]\n",
    "            print()\n",
    "\n",
    "            # Train classifier\n",
    "            rcca = pyntbci.classifiers.rCCA(stimulus=V, fs=fs, event=event, encoding_length=encoding_length,\n",
    "                                            onset_event=onset_event, ensemble=ensemble)\n",
    "            print(\"Shape of X_trn:\", X_trn.shape)\n",
    "            print(\"Shape of y_trn:\", y_trn.shape)\n",
    "            rcca.fit(X_trn, y_trn)\n",
    "\n",
    "            # Apply classifier\n",
    "            yh_tst = rcca.predict(X_tst)\n",
    "            print(\"shape of X_tst:\", X_tst.shape)\n",
    "\n",
    "            # Compute accuracy\n",
    "            accuracy[i_subject, i_task, i_fold] = np.mean(yh_tst == y_tst)\n",
    "            \n",
    "        # Compute mean and standard error\n",
    "        fold_accuracies = accuracy[i_subject, i_task, :]\n",
    "        accuracy_mean[i_subject, i_task] = fold_accuracies.mean()\n",
    "        accuracy_se[i_subject, i_task] = np.round(fold_accuracies.std() / np.sqrt(n_folds), 2)\n",
    "        \n",
    "        print(f\"{accuracy[i_subject, i_task, :].mean():.3f}\", end=\"\\t\")\n",
    "    print()\n",
    "\n",
    "print(f\"Average:\\tovert: {accuracy[:, 0, :].mean():.3f}\\tcovert: {accuracy[:, 1, :].mean():.3f}\")\n",
    "\n",
    "# np.savez(os.path.join(save_dir, \"c-VEP_rcca.npz\"), accuracy=accuracy, accuracy_mean=accuracy_mean, accuracy_se=accuracy_se)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e93a1ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'channels is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fn):\n\u001b[1;32m     22\u001b[0m             tmp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(fn)\n\u001b[0;32m---> 23\u001b[0m             channel_names \u001b[38;5;241m=\u001b[39m \u001b[43mtmp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchannels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# adjust if channel names stored under a different key\u001b[39;00m\n\u001b[1;32m     24\u001b[0m             all_channel_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mset\u001b[39m(channel_names))\n\u001b[1;32m     26\u001b[0m common_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;241m*\u001b[39mall_channel_names)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39/lib/python3.9/site-packages/numpy/lib/npyio.py:263\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'channels is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_dir = '/Users/juliette/Desktop/thesis/preprocessing/c-VEP_preprocessing'\n",
    "subjects = [\n",
    "    \"VPpdia\", \"VPpdib\", \"VPpdic\", \"VPpdid\", \"VPpdie\", \"VPpdif\", \"VPpdig\", \"VPpdih\", \"VPpdii\", \"VPpdij\", \"VPpdik\",\n",
    "    \"VPpdil\", \"VPpdim\", \"VPpdin\", \"VPpdio\", \"VPpdip\", \"VPpdiq\", \"VPpdir\", \"VPpdis\", \"VPpdit\", \"VPpdiu\", \"VPpdiv\",\n",
    "    \"VPpdiw\", \"VPpdix\", \"VPpdiy\", \"VPpdiz\", \"VPpdiza\", \"VPpdizb\", \"VPpdizc\"\n",
    "]\n",
    "tasks = [\"overt\", \"covert\"]\n",
    "\n",
    "all_X = []\n",
    "all_y = []\n",
    "\n",
    "# Example if you have channel names per file\n",
    "all_channel_names = []\n",
    "\n",
    "for subject in subjects:\n",
    "    for task in tasks:\n",
    "        fn = os.path.join(data_dir, f\"sub-{subject}_task-{task}.npz\")\n",
    "        if os.path.exists(fn):\n",
    "            tmp = np.load(fn)\n",
    "            channel_names = tmp[\"channels\"]  # adjust if channel names stored under a different key\n",
    "            all_channel_names.append(set(channel_names))\n",
    "\n",
    "common_channels = set.intersection(*all_channel_names)\n",
    "print(f\"Number of common channels: {len(common_channels)}\")\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "# Concatenate all data along trials axis (axis=0)\n",
    "X_all = np.concatenate(all_X, axis=0)\n",
    "y_all = np.concatenate(all_y, axis=0)\n",
    "\n",
    "# Calculate total samples and features\n",
    "n_samples = X_all.shape[0]  # total trials/samples\n",
    "n_features = X_all.shape[1] * X_all.shape[2]  # channels × timepoints\n",
    "\n",
    "ratio = n_samples / n_features\n",
    "\n",
    "print(f\"Total samples (trials): {n_samples}\")\n",
    "print(f\"Total features (channels × timepoints): {n_features}\")\n",
    "print(f\"Sample to feature ratio: {ratio:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d03427",
   "metadata": {},
   "source": [
    "# Applying ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e93681a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPpdia\tovert: 1.000\tcovert: 0.562\t\n",
      "VPpdib\tovert: 1.000\tcovert: 0.600\t\n",
      "VPpdic\tovert: 1.000\tcovert: 0.588\t\n",
      "VPpdid\tovert: 1.000\tcovert: 0.613\t\n",
      "VPpdie\tovert: 1.000\tcovert: 0.637\t\n",
      "VPpdif\tovert: 1.000\tcovert: 0.713\t\n",
      "VPpdig\tovert: 1.000\tcovert: 0.725\t\n",
      "VPpdih\tovert: 1.000\tcovert: 0.725\t\n",
      "VPpdii\tovert: 1.000\tcovert: 0.688\t\n",
      "VPpdij\tovert: 1.000\tcovert: 0.662\t\n",
      "VPpdik\tovert: 1.000\tcovert: 0.725\t\n",
      "VPpdil\tovert: 1.000\tcovert: 0.588\t\n",
      "VPpdim\tovert: 1.000\tcovert: 0.600\t\n",
      "VPpdin\tovert: 0.950\tcovert: 0.850\t\n",
      "VPpdio\tovert: 1.000\tcovert: 0.675\t\n",
      "VPpdip\tovert: 1.000\tcovert: 0.862\t\n",
      "VPpdiq\tovert: 1.000\tcovert: 0.600\t\n",
      "VPpdir\tovert: 1.000\tcovert: 0.800\t\n",
      "VPpdis\tovert: 0.950\tcovert: 0.575\t\n",
      "VPpdit\tovert: 1.000\tcovert: 0.775\t\n",
      "VPpdiu\tovert: 1.000\tcovert: 0.700\t\n",
      "VPpdiv\tovert: 1.000\tcovert: 0.800\t\n",
      "VPpdiw\tovert: 0.950\tcovert: 0.550\t\n",
      "VPpdix\tovert: 1.000\tcovert: 0.662\t\n",
      "VPpdiy\tovert: 1.000\tcovert: 0.488\t\n",
      "VPpdiz\tovert: 1.000\tcovert: 0.575\t\n",
      "VPpdiza\tovert: 1.000\tcovert: 0.588\t\n",
      "VPpdizb\tovert: 1.000\tcovert: 0.600\t\n",
      "VPpdizc\tovert: 1.000\tcovert: 0.650\t\n",
      "Average:\tovert: 0.995\tcovert: 0.661\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Jordy Thielen (jordy.thielen@donders.ru.nl)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import mne\n",
    "import pandas as pd\n",
    "import pyntbci\n",
    "\n",
    "data_dir = '/Users/juliette/Desktop/thesis/preprocessing/c-VEP_preprocessing/c-VEP_ICA'\n",
    "save_dir = '/Users/juliette/Desktop/thesis/results/c-VEP/c-VEP_ICA'\n",
    "subjects = [\n",
    "    \"VPpdia\", \"VPpdib\", \"VPpdic\", \"VPpdid\", \"VPpdie\", \"VPpdif\", \"VPpdig\", \"VPpdih\", \"VPpdii\", \"VPpdij\", \"VPpdik\",\n",
    "    \"VPpdil\", \"VPpdim\", \"VPpdin\", \"VPpdio\", \"VPpdip\", \"VPpdiq\", \"VPpdir\", \"VPpdis\", \"VPpdit\", \"VPpdiu\", \"VPpdiv\",\n",
    "    \"VPpdiw\", \"VPpdix\", \"VPpdiy\", \"VPpdiz\", \"VPpdiza\", \"VPpdizb\", \"VPpdizc\"\n",
    "]\n",
    "\n",
    "tasks = [\"overt\", \"covert\"]\n",
    "\n",
    "event = \"dur\"\n",
    "onset_event = True\n",
    "encoding_length = 0.3\n",
    "ensemble = True\n",
    "n_folds = 4\n",
    "\n",
    "# Define performance arrays\n",
    "accuracy = np.zeros((len(subjects), len(tasks), n_folds))\n",
    "accuracy_se = np.zeros((len(subjects), len(tasks)))\n",
    "accuracy_mean = np.zeros((len(subjects), len(tasks)))\n",
    "\n",
    "# Loop participants\n",
    "for i_subject, subject in enumerate(subjects):\n",
    "    print(f\"{subject}\", end=\"\\t\")\n",
    "\n",
    "    # Loop tasks\n",
    "    for i_task, task in enumerate(tasks):\n",
    "        print(f\"{task}: \", end=\"\")\n",
    "\n",
    "        # Load data\n",
    "        fn = os.path.join(data_dir, f\"sub-{subject}_task-{task}_ICA.npz\")\n",
    "        tmp = np.load(fn)\n",
    "        fs = int(tmp[\"fs\"])\n",
    "        X = tmp[\"X\"]\n",
    "        y = tmp[\"y\"]\n",
    "        V = tmp[\"V\"]\n",
    "\n",
    "        # Cross-validation\n",
    "        folds = np.repeat(np.arange(n_folds), int(X.shape[0] / n_folds))\n",
    "        for i_fold in range(n_folds):\n",
    "            # Split data to train and test set\n",
    "            X_trn, y_trn = X[folds != i_fold, :, :], y[folds != i_fold]\n",
    "            X_tst, y_tst = X[folds == i_fold, :, :], y[folds == i_fold]\n",
    "\n",
    "            # Train classifier\n",
    "            rcca = pyntbci.classifiers.rCCA(stimulus=V, fs=fs, event=event, encoding_length=encoding_length,\n",
    "                                            onset_event=onset_event, ensemble=ensemble)\n",
    "            rcca.fit(X_trn, y_trn)\n",
    "\n",
    "            # Apply classifier\n",
    "            yh_tst = rcca.predict(X_tst)\n",
    "\n",
    "            # Compute accuracy\n",
    "            accuracy[i_subject, i_task, i_fold] = np.mean(yh_tst == y_tst)\n",
    "            \n",
    "        # Compute mean and standard error\n",
    "        fold_accuracies = accuracy[i_subject, i_task, :]\n",
    "        accuracy_mean[i_subject, i_task] = fold_accuracies.mean()\n",
    "        accuracy_se[i_subject, i_task] = np.round(fold_accuracies.std() / np.sqrt(n_folds), 2)\n",
    "        \n",
    "        print(f\"{accuracy[i_subject, i_task, :].mean():.3f}\", end=\"\\t\")\n",
    "    print()\n",
    "\n",
    "print(f\"Average:\\tovert: {accuracy[:, 0, :].mean():.3f}\\tcovert: {accuracy[:, 1, :].mean():.3f}\")\n",
    "\n",
    "np.savez(os.path.join(save_dir, \"c-VEP_rcca_ICA.npz\"), accuracy=accuracy, accuracy_mean=accuracy_mean, accuracy_se=accuracy_se)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c583b18f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
