{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b88d06",
   "metadata": {},
   "source": [
    "# Steps from Egan's paper\n",
    "\n",
    "1. Preprocessing\n",
    "The paper also proposes preprocessing steps, however I follow the preprocessing steps that we already did.\n",
    "\n",
    "2. Epoching\n",
    "Create trial-length epochs for alpha, these span the entire trial (20 seconds), they start 0.5 seconds before the trial until 0.5 seconds after the trial. For the P300 aalysis, create target-locked epochs, starting 0.25 seconds before the target and ending 1 second after the target.\n",
    "\n",
    "3. Frequency Analysis for Alpha Band\n",
    "Perform frequency analysis using a 2-second rectangular sliding window across each trial-length epoch in steps of 0.5 seconds. For each window, apply a FFT to the data from each electrode. Extract the average amplitude between 8–13 Hz (alpha band) for each step. Average the features within a selected set of electrodes to obtain the  alpha values that will be used for classification.\n",
    "\n",
    "4. ERP Feature Extraction for P300\n",
    "Separate target-locked epochs for attended and unattended stimuli. Average the target-locked epochs across occurrences of attended and unattended targets. Baseline correct the ERP by subtracting the average of the 0.5 seconds preceding the appearance of the target from the remaining data (0–0.75 s).\n",
    "\n",
    "5. Combine the frequency domain features from the alpha-band analysis with the ERP features from the P300 analysis.\n",
    "Ensure that the features are concatenated in a way that is suitable for classification, typically forming a combined feature vector for each trial.\n",
    "\n",
    "6. Classification\n",
    "Train an LDA classifier using the hybrid feature set (alpha-band + P300 ERP features), possibly with ledoit wolf regularization. Use cross-validation to evaluate classification performance and avoid overfitting.\n",
    "\n",
    "7. Evaluation\n",
    "Evaluate the classification performance using appropriate metrics such as accuracy, precision, recall, F1 score, or ROC curves.\n",
    "\n",
    "### Questions:\n",
    "Should I use binning of the ERP epochs?\n",
    "\n",
    "# Approach 1: Most similar to Egan's paper:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c0400",
   "metadata": {},
   "source": [
    "c-VEP --> per electrode (scalp map links en rechts) correlatie met die trial en template links. Voor links heb je dan Rho links en rechts Rho rechts. Geen CCA, handmatig kiezen van spatieel filter. mV^2 mV en correlatie.\n",
    "P300 pynthbci to epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "11805555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing VPpdia...\n",
      "  Fold 1/4\n",
      "ERP_trn: [[[-2.20337902e-07 -6.45332767e-08  4.85096478e-08 ... -3.18792233e-07\n",
      "   -2.63607704e-07 -4.45821188e-08]\n",
      "  [-2.20337902e-07 -6.45332767e-08  4.85096478e-08 ... -3.18792233e-07\n",
      "   -2.63607704e-07 -4.45821188e-08]]\n",
      "\n",
      " [[ 3.36258625e-07  1.78890340e-07  1.33797484e-07 ... -2.42158882e-07\n",
      "   -2.82308764e-07 -7.80666164e-08]\n",
      "  [ 3.36258625e-07  1.78890340e-07  1.33797484e-07 ... -2.42158882e-07\n",
      "   -2.82308764e-07 -7.80666164e-08]]\n",
      "\n",
      " [[-8.17316834e-08 -4.82179499e-08  1.51316219e-07 ...  1.25846834e-07\n",
      "    6.04532904e-08  2.42081740e-08]\n",
      "  [-8.17316834e-08 -4.82179499e-08  1.51316219e-07 ...  1.25846834e-07\n",
      "    6.04532904e-08  2.42081740e-08]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.74897451e-07  4.41581187e-07  2.48312974e-07 ... -6.97453142e-07\n",
      "   -7.16567370e-07 -3.22376195e-07]\n",
      "  [ 2.74897451e-07  4.41581187e-07  2.48312974e-07 ... -6.97453142e-07\n",
      "   -7.16567370e-07 -3.22376195e-07]]\n",
      "\n",
      " [[-6.29110097e-08 -1.98116739e-07 -2.03052887e-07 ... -2.66552698e-07\n",
      "    5.50207625e-08  3.88463915e-07]\n",
      "  [-6.29110097e-08 -1.98116739e-07 -2.03052887e-07 ... -2.66552698e-07\n",
      "    5.50207625e-08  3.88463915e-07]]\n",
      "\n",
      " [[-6.80037721e-08  6.25752972e-08  1.66503916e-07 ...  6.43573579e-08\n",
      "   -1.70252184e-07 -3.01693726e-07]\n",
      "  [-6.80037721e-08  6.25752972e-08  1.66503916e-07 ...  6.43573579e-08\n",
      "   -1.70252184e-07 -3.01693726e-07]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 168\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERP_trn:\u001b[39m\u001b[38;5;124m\"\u001b[39m, erp_trn)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# --- STEP 5: FEATURE FUSION ---\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m F_trn \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43malpha_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merp_trn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m F_tst \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([alpha_tst, erp_tst], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Handle NaNs, replaces any NaN values with 0\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mne.time_frequency import psd_array_welch\n",
    "import mne\n",
    "\n",
    "# Suppress warnings from MNE\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# Define path\n",
    "file_dir = '/Users/juliette/Desktop/thesis/preprocessing/hybrid_preprocessing'\n",
    "decoding_results_dir = '/Users/juliette/Desktop/thesis/results/alpha+p300'\n",
    "\n",
    "# Set parameters\n",
    "window_size = 2     # in seconds for alpha-band sliding window\n",
    "step_size = 0.5     # sliding step\n",
    "min_bin, max_bin = 8, 13  # alpha band\n",
    "\n",
    "# Subjects\n",
    "subjects = [\"VPpdia\", \"VPpdib\", \"VPpdic\", \"VPpdid\", \"VPpdie\", \"VPpdif\", \"VPpdig\", \"VPpdih\", \"VPpdii\", \"VPpdij\",\n",
    "            \"VPpdik\", \"VPpdil\", \"VPpdim\", \"VPpdin\", \"VPpdio\", \"VPpdip\", \"VPpdiq\", \"VPpdir\", \"VPpdis\", \"VPpdit\",\n",
    "            \"VPpdiu\", \"VPpdiv\", \"VPpdiw\", \"VPpdix\", \"VPpdiy\", \"VPpdiz\", \"VPpdiza\", \"VPpdizb\", \"VPpdizc\"]\n",
    "\n",
    "# Initialize results storage\n",
    "results = []\n",
    "\n",
    "# Loop over the subjects\n",
    "for subject in subjects:\n",
    "    print(f\"Processing {subject}...\")\n",
    "\n",
    "    # Load preprocessed ICA-cleaned data\n",
    "    fn = os.path.join(file_dir, f\"sub-{subject}_task-covert_c-VEP+P300_ICA.npz\")\n",
    "    tmp = np.load(fn, allow_pickle=True)\n",
    "\n",
    "    X = tmp[\"X\"]  # shape: trials × channels × samples\n",
    "    y = tmp[\"y\"]  # binary trial label (e.g., attention)\n",
    "    z = tmp[\"z\"]  # stimulus labels\n",
    "    V = tmp[\"V\"]  # marker stream, used for timing info\n",
    "    fs = int(tmp[\"fs\"].flatten()[0])\n",
    "    n_trials, n_channels, n_samples = X.shape\n",
    "\n",
    "    # Split folds\n",
    "    fold_accuracies = []\n",
    "    n_folds = 4\n",
    "    n_per_fold = n_trials // n_folds\n",
    "    folds = np.repeat(np.arange(n_folds), n_per_fold)\n",
    "\n",
    "    for i_fold in range(n_folds):\n",
    "        print(f\"  Fold {i_fold + 1}/{n_folds}\")\n",
    "\n",
    "        # Train/test split\n",
    "        X_trn, y_trn, z_trn = X[folds != i_fold,:,:], y[folds != i_fold], z[folds != i_fold]\n",
    "        X_tst, y_tst, z_tst = X[folds == i_fold,:,:], y[folds == i_fold], z[folds == i_fold]\n",
    "\n",
    "        # Frequency analysis for the alpha band\n",
    "        def extract_alpha(X_trials):\n",
    "            alpha_feats = []\n",
    "            for trial in X_trials:\n",
    "                trial_alpha = [] # This variable will hold the alpha power values for each time window in the current trial\n",
    "                total_duration = n_samples/fs\n",
    "        \n",
    "                for start in np.arange(0, total_duration - window_size, step_size):\n",
    "                    start_ix = int(start * fs) # convert the starting times to sample indices\n",
    "                    stop_ix = int(start_ix + window_size * fs)\n",
    "                    \n",
    "                    # If stop_ix exceeds the time samples in the trial the window is too large and it stops\n",
    "                    if stop_ix > trial.shape[1]:\n",
    "                        break\n",
    "                    \n",
    "                    # This contains the EEG data for the selected time window\n",
    "                    # It is sliced from the trial array for all channels, and the selected time window\n",
    "                    segment = trial[:, start_ix:stop_ix]\n",
    "                    \n",
    "                    psds, freqs = psd_array_welch(\n",
    "                        segment, sfreq=fs, fmin=min_bin, fmax=max_bin, n_per_seg=segment.shape[1] # The number of points per segment \n",
    "                    )                                                                             # is equal to the length of the segment\n",
    "                    alpha_power = psds.mean(axis=1)  # average power across the frequency bins in the alpha band across channels\n",
    "                    trial_alpha.append(alpha_power)\n",
    "                trial_alpha = np.mean(trial_alpha, axis=0)  # calculate single alpha power feature for the trial\n",
    "                alpha_feats.append(trial_alpha)\n",
    "            return np.array(alpha_feats)  # shape: (trials × channels)\n",
    "\n",
    "        alpha_trn = extract_alpha(X_trn)\n",
    "        alpha_tst = extract_alpha(X_tst)\n",
    "\n",
    "        # --- STEP 4: ERP FEATURE EXTRACTION FOR P300 ---\n",
    "        def extract_erp_no_bins(X_trials, z_trials, y, fs, n_channels, n_bins=6):\n",
    "            # An empty list that will hold the ERP features for each trial\n",
    "            erp_feats = []\n",
    "\n",
    "            # Extracting all the stimulus coding\n",
    "            side_tst = z_trials[:, :, :]  # All epochs for each trial (n_trials, n_epochs, 2)\n",
    "\n",
    "            # Identify left and right target events\n",
    "            z_left = side_tst[:, :, 0] == 1  # Left target (index 0)\n",
    "            z_right = side_tst[:, :, 1] == 1  # Right target (index 1)\n",
    "\n",
    "            # Loop through each trial, stimulus coding and attended side label\n",
    "            for trial, z, target_side in zip(X_trials, z_trials, y):\n",
    "                # Determine attended and unattended sides\n",
    "                if target_side == 0:  # Attending to left\n",
    "                    attended_side = z_left  # Left target is attended\n",
    "                    unattended_side = z_right  # Right target is unattended\n",
    "                else:  # Attending to right\n",
    "                    attended_side = z_right  # Right target is attended\n",
    "                    unattended_side = z_left  # Left target is unattended\n",
    "\n",
    "                # Find the indices of targets on the attended side\n",
    "                target_indices_attended = np.where(attended_side == 1)[0]\n",
    "                # Find the indices of targets on the unattended side\n",
    "                target_indices_unattended = np.where(unattended_side == 1)[0]\n",
    "\n",
    "                # If no target indices are found for both the attended and unattended sides, append a placeholder\n",
    "                if len(target_indices_attended) == 0 and len(target_indices_unattended) == 0:\n",
    "                    erp_feats.append(np.zeros(n_channels * 2))  # Placeholder (attended + unattended)\n",
    "                    continue\n",
    "\n",
    "                # Initialize arrays that will hold the ERP features for the attended and unattended targets\n",
    "                feat_attended = np.zeros(n_channels)\n",
    "                feat_unattended = np.zeros(n_channels)\n",
    "\n",
    "                # Process attended target\n",
    "                if len(target_indices_attended) > 0:\n",
    "                    # Extract the first target index, which gives the position of the attended target\n",
    "                    t_ix_attended = target_indices_attended[0]\n",
    "                    start_ix_attended = int(t_ix_attended - 0.25 * fs)  # 250 ms before the target (baseline period)\n",
    "                    stop_ix_attended = int(t_ix_attended + 1.0 * fs)    # 1000 ms after the target\n",
    "\n",
    "                    # Ensure indices are within the valid range for the current trial\n",
    "                    start_ix_attended = max(0, start_ix_attended)\n",
    "                    stop_ix_attended = min(trial.shape[1], stop_ix_attended)\n",
    "\n",
    "                    # Extract the EEG data around the attended target using the indices\n",
    "                    epoch_attended = trial[:, start_ix_attended:stop_ix_attended]\n",
    "\n",
    "                    # Compute the ERP feature for the attended target by averaging the EEG data across the time axis\n",
    "                    feat_attended = epoch_attended.mean(axis=1)\n",
    "\n",
    "                # Process unattended target\n",
    "                if len(target_indices_unattended) > 0:\n",
    "                    # Extract the first target index, which gives the position of the unattended target\n",
    "                    t_ix_unattended = target_indices_unattended[0]\n",
    "                    start_ix_unattended = int((t_ix_unattended - 0.25) * fs)  # 250 ms before the target (baseline period)\n",
    "                    stop_ix_unattended = int(t_ix_unattended + 1.0 * fs)    # 1000 ms after the target\n",
    "\n",
    "                    # Ensure indices are within the valid range for the current trial\n",
    "                    start_ix_unattended = max(0, start_ix_unattended)\n",
    "                    stop_ix_unattended = min(trial.shape[1], stop_ix_unattended)\n",
    "\n",
    "                    # Extract the EEG data around the unattended target using the indices\n",
    "                    epoch_unattended = trial[:, start_ix_unattended:stop_ix_unattended]\n",
    "\n",
    "                    # Compute the ERP feature for the unattended target by averaging the EEG data across the time axis\n",
    "                    feat_unattended = epoch_unattended.mean(axis=1)\n",
    "\n",
    "                # Concatenate attended and unattended features and append to the list\n",
    "                erp_feats.append(np.concatenate([feat_attended, feat_unattended]))\n",
    "\n",
    "            return np.array(erp_feats)\n",
    "\n",
    "\n",
    "        # Extract ERP features for training and testing\n",
    "        erp_trn = extract_erp_no_bins(X_trn, z_trn, y_trn, fs, n_channels)\n",
    "        erp_tst = extract_erp_no_bins(X_tst, z_tst, y_tst, fs, n_channels)\n",
    "        print(\"ERP_trn:\", erp_trn)\n",
    "\n",
    "        # --- STEP 5: FEATURE FUSION ---\n",
    "        F_trn = np.concatenate([alpha_trn, erp_trn], axis=1)\n",
    "        F_tst = np.concatenate([alpha_tst, erp_tst], axis=1)\n",
    "\n",
    "        # Handle NaNs, replaces any NaN values with 0\n",
    "        F_trn[np.isnan(F_trn)] = 0\n",
    "        F_tst[np.isnan(F_tst)] = 0\n",
    "\n",
    "        # Normalize, it scales the features so that they have a mean of 0 and a standard deviation of 1\n",
    "        scaler = StandardScaler()\n",
    "        F_trn = scaler.fit_transform(F_trn)\n",
    "        F_tst = scaler.transform(F_tst)\n",
    "\n",
    "        # --- STEP 6: CLASSIFICATION ---\n",
    "        clf = LDA(solver='lsqr', shrinkage='auto')  # Ledoit-Wolf shrinkage\n",
    "        clf.fit(F_trn, y_trn)\n",
    "        y_pred = clf.predict(F_tst)\n",
    "\n",
    "        acc = np.mean(y_pred == y_tst)\n",
    "        fold_accuracies.append(acc)\n",
    "        print(f\"    Fold accuracy: {acc:.2f}\")\n",
    "\n",
    "    # --- STEP 7: SAVE RESULTS FOR THIS SUBJECT ---\n",
    "    acc_mean = np.round(np.mean(fold_accuracies), 2)\n",
    "    acc_se = np.round(np.std(fold_accuracies) / np.sqrt(n_folds), 2)\n",
    "    results.append((subject, acc_mean, acc_se))\n",
    "    print(f\"{subject}: Accuracy = {acc_mean:.2f}, SE = {acc_se:.2f}\")\n",
    "\n",
    "    \n",
    "# --- STEP 8: AVERAGE ACCURACY OVER ALL SUBJECTS ---\n",
    "all_accuracies = [result[1] for result in results]\n",
    "mean_accuracy_all = np.mean(all_accuracies)\n",
    "se_accuracy_all = np.std(all_accuracies) / np.sqrt(len(all_accuracies))\n",
    "\n",
    "print(f\"\\nAverage Accuracy across all subjects: {mean_accuracy_all:.2f}\")\n",
    "print(f\"Standard Error of Accuracy: {se_accuracy_all:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2985f2e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_ix_attended: 11\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 12\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 9\n",
      "t_ix_attended: 3\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 8\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 11\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 12\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 9\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 3\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 8\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 11\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 12\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 9\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 3\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 8\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 11\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 12\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 9\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 3\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 8\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 11\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 12\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 9\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 3\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 8\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 11\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 12\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 9\n",
      "t_ix_attended: 3\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 8\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 11\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 12\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 4\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 9\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 3\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 8\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 11\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 12\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 5\n",
      "t_ix_attended: 7\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 9\n",
      "t_ix_unattended: 2\n",
      "t_ix_attended: 3\n",
      "t_ix_unattended: 7\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 4\n",
      "t_ix_attended: 2\n",
      "t_ix_unattended: 8\n",
      "t_ix_attended: 5\n",
      "t_ix_unattended: 4\n",
      "ERP_trn: [[[-4.20356943e-07 -2.53292355e-08  8.15280813e-08 ...  8.61582733e-08\n",
      "    3.96577052e-07  4.64165904e-07]\n",
      "  [-4.20356943e-07 -2.53292355e-08  8.15280813e-08 ...  8.61582733e-08\n",
      "    3.96577052e-07  4.64165904e-07]]\n",
      "\n",
      " [[ 1.03105281e-06  5.67525423e-07 -2.62337533e-08 ...  8.21583333e-07\n",
      "    6.16335090e-07  2.18739969e-07]\n",
      "  [ 1.03105281e-06  5.67525423e-07 -2.62337533e-08 ...  8.21583333e-07\n",
      "    6.16335090e-07  2.18739969e-07]]\n",
      "\n",
      " [[-5.50502898e-07 -6.70272465e-07 -2.02086086e-07 ...  2.97596956e-07\n",
      "    5.16280125e-07  4.22108517e-07]\n",
      "  [-5.50502898e-07 -6.70272465e-07 -2.02086086e-07 ...  2.97596956e-07\n",
      "    5.16280125e-07  4.22108517e-07]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.30306496e-07  9.27195696e-07  1.35687500e-06 ...  8.52925360e-07\n",
      "    3.49234722e-07 -1.54303818e-07]\n",
      "  [ 3.30306496e-07  9.27195696e-07  1.35687500e-06 ...  8.52925360e-07\n",
      "    3.49234722e-07 -1.54303818e-07]]\n",
      "\n",
      " [[ 7.39352788e-07  4.22191159e-07  5.02751298e-07 ... -9.87117754e-08\n",
      "   -7.60822198e-07 -1.52416002e-06]\n",
      "  [ 7.39352788e-07  4.22191159e-07  5.02751298e-07 ... -9.87117754e-08\n",
      "   -7.60822198e-07 -1.52416002e-06]]\n",
      "\n",
      " [[-7.32964526e-07 -8.88752664e-07 -1.07510962e-06 ... -3.81181798e-08\n",
      "   -2.95273939e-07 -4.51136409e-08]\n",
      "  [-7.32964526e-07 -8.88752664e-07 -1.07510962e-06 ... -3.81181798e-08\n",
      "   -2.95273939e-07 -4.51136409e-08]]]\n"
     ]
    }
   ],
   "source": [
    "def extract_erp_no_bins(X_trials, z_trials, y, fs, n_channels, amplitude_threshold=40e-6, start_sample_offset=-24, end_sample_offset=84, step_size=30):\n",
    "    # An empty list that will hold the ERP features for each trial\n",
    "    erp_feats = []\n",
    "\n",
    "    # Loop through each trial, stimulus coding, and attended side label\n",
    "    for trial, z, target_side in zip(X_trials, z_trials, y):\n",
    "        cued_side = target_side  # Assuming 'y' contains the trial information about which side (left or right)\n",
    "\n",
    "        # Create event vectors for left and right targets\n",
    "        left_targets = z[:, 0]  # Assuming z contains the event markers, where 0 = left, 1 = right\n",
    "        right_targets = z[:, 1]\n",
    "        attended_stimuli = z[:, cued_side]  # Select the cued target side\n",
    "\n",
    "        # Identify left and right target events\n",
    "        z_left = left_targets == 1\n",
    "        z_right = right_targets == 1\n",
    "\n",
    "        # Determine attended and unattended sides\n",
    "        if target_side == 0:  # Attending to left\n",
    "            attended_side = z_left  # Left target is attended\n",
    "            unattended_side = z_right  # Right target is unattended\n",
    "        else:  # Attending to right\n",
    "            attended_side = z_right  # Right target is attended\n",
    "            unattended_side = z_left  # Left target is unattended\n",
    "\n",
    "        # Find the indices of targets on the attended side\n",
    "        target_indices_attended = np.where(attended_side == 1)[0]\n",
    "        # Find the indices of targets on the unattended side\n",
    "        target_indices_unattended = np.where(unattended_side == 1)[0]\n",
    "\n",
    "        # If no target indices are found for both the attended and unattended sides, append a placeholder\n",
    "        if len(target_indices_attended) == 0 and len(target_indices_unattended) == 0:\n",
    "            erp_feats.append(np.zeros(n_channels * 2))  # Placeholder (attended + unattended)\n",
    "            continue\n",
    "\n",
    "        # Initialize arrays that will hold the ERP features for the attended and unattended targets\n",
    "        feat_attended = np.zeros(n_channels)\n",
    "        feat_unattended = np.zeros(n_channels)\n",
    "\n",
    "        # Process attended target\n",
    "        if len(target_indices_attended) > 0:\n",
    "            # Extract the first target index, which gives the position of the attended target\n",
    "            t_ix_attended = target_indices_attended[0]\n",
    "            print(\"t_ix_attended:\", t_ix_attended)\n",
    "            \n",
    "            # Extract epochs around the attended target\n",
    "            epoch_attended, _ = extract_epochs(trial[None, :, :], start_idx=120, end_idx=2520, step_size=30, \n",
    "                   start_sample_offset=-24, end_sample_offset=84, \n",
    "                   amplitude_threshold=40e-6)\n",
    "            \n",
    "            # Compute the ERP feature for the attended target by averaging the EEG data across the time axis\n",
    "            feat_attended = epoch_attended.mean(axis=(1, 2))  # Averaging across epochs and channels\n",
    "\n",
    "        # Process unattended target\n",
    "        if len(target_indices_unattended) > 0:\n",
    "            # Extract the first target index, which gives the position of the unattended target\n",
    "            t_ix_unattended = target_indices_unattended[0]\n",
    "            print(\"t_ix_unattended:\", t_ix_unattended)\n",
    "            \n",
    "            # Extract epochs around the unattended target\n",
    "            epoch_unattended, _ = extract_epochs(trial[None, :, :], start_idx=120, end_idx=2520, step_size=30, \n",
    "                   start_sample_offset=-24, end_sample_offset=84, \n",
    "                   amplitude_threshold=40e-6)\n",
    "            \n",
    "            # Compute the ERP feature for the unattended target by averaging the EEG data across the time axis\n",
    "            feat_unattended = epoch_unattended.mean(axis=(1, 2))  # Averaging across epochs and channels\n",
    "\n",
    "        # Concatenate attended and unattended features and append to the list\n",
    "        erp_feats.append(np.concatenate([feat_attended, feat_unattended]))\n",
    "\n",
    "    return np.array(erp_feats)\n",
    "\n",
    "# Example usage\n",
    "erp_trn = extract_erp_no_bins(X_trn, z_trn, y_trn, fs, n_channels)\n",
    "erp_tst = extract_erp_no_bins(X_tst, z_tst, y_tst, fs, n_channels)\n",
    "\n",
    "# Print the result\n",
    "print(\"ERP_trn:\", erp_trn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de1569",
   "metadata": {},
   "source": [
    "# Approach 2: Concatenation of scores\n",
    "This approach has a lower performance, so I prefer to use the previous approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "11e6adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_epochs(X, start_idx=120, end_idx=2520, step_size=30, \n",
    "                   start_sample_offset=-24, end_sample_offset=84, \n",
    "                   amplitude_threshold=40e-6):\n",
    "    \"\"\"\n",
    "    Function to extract epochs from time-series data for ERP features, \n",
    "    baseline-correct each epoch, and identify bad epochs based on amplitude threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Input data array of shape (n_trials, n_channels, n_samples)\n",
    "    - start_idx: The starting sample index for the first epoch (default=120)\n",
    "    - end_idx: The last sample index where the final epoch starts (default=2520)\n",
    "    - step_size: Step size in samples, corresponding to the sliding window (default=30)\n",
    "    - start_sample_offset: The offset for the start of the time window (default=-24, corresponds to -200 ms)\n",
    "    - end_sample_offset: The offset for the end of the time window (default=84, corresponds to 700 ms)\n",
    "    - amplitude_threshold: Threshold for identifying bad epochs based on amplitude range (default=100)\n",
    "    \n",
    "    Returns:\n",
    "    - output_matrix: A 4D array of extracted and baseline-corrected epochs of shape \n",
    "                     (n_trials, n_epochs, n_channels, window_size)\n",
    "    - bad_epochs_idx: List of indices of bad epochs for each trial and channel \n",
    "                      where amplitude range exceeds the threshold.\n",
    "    \"\"\"\n",
    "    # Check input dimensions\n",
    "    if X.ndim != 3:\n",
    "        raise ValueError(f\"Input X must have 3 dimensions (n_trials, n_channels, n_samples), but got {X.ndim} dimensions.\")\n",
    "    \n",
    "    n_trials, n_channels, n_samples = X.shape\n",
    "    window_size = end_sample_offset + np.abs(start_sample_offset)  # 108 samples\n",
    "    epoch_timestamps = np.arange(start_idx, end_idx, step_size)    # (80,)\n",
    "    n_epochs = len(epoch_timestamps)\n",
    "    \n",
    "    # Initialize the output matrix for the epochs and a list for bad epoch indices\n",
    "    output_matrix = np.zeros((n_trials, n_epochs, n_channels, window_size))\n",
    "    bad_epochs_idx = []  # To store (trial, epoch, channel) indices of bad epochs\n",
    "    \n",
    "    # Loop over trials, channels, and epochs to extract and baseline-correct the windows\n",
    "    for i_trial in range(n_trials):\n",
    "        for i_channel in range(n_channels):\n",
    "            data = X[i_trial, i_channel, :]\n",
    "\n",
    "            for i_epoch, t in enumerate(epoch_timestamps):\n",
    "                epoch_start_idx = t + start_sample_offset  # Start at t - 24 samples (-200 ms)\n",
    "                epoch_end_idx = t + end_sample_offset      # End at t + 84 samples (700 ms)\n",
    "                \n",
    "                # Ensure the window stays within bounds\n",
    "                if epoch_start_idx >= 0 and epoch_end_idx <= n_samples:\n",
    "                    epoch_data = data[epoch_start_idx:epoch_end_idx]\n",
    "                    \n",
    "                    # Baseline correction\n",
    "                    baseline_mean = np.mean(epoch_data[:25])\n",
    "                    epoch_data = epoch_data - baseline_mean\n",
    "                    \n",
    "                    # Store the epoch in the output matrix\n",
    "                    output_matrix[i_trial, i_epoch, i_channel, :] = epoch_data\n",
    "                    \n",
    "                    # Check amplitude range after baseline subtraction\n",
    "                    min_amp, max_amp = np.min(epoch_data), np.max(epoch_data)\n",
    "                    amplitude_range = max_amp - min_amp\n",
    "                    \n",
    "                    # Log bad epochs if amplitude range exceeds threshold\n",
    "                    if amplitude_range > amplitude_threshold:\n",
    "                        bad_epochs_idx.append((i_trial, i_epoch, i_channel))\n",
    "    \n",
    "    # Return the 4D output matrix and the indices of bad epochs\n",
    "    return output_matrix, bad_epochs_idx\n",
    "\n",
    "def mark_bad_epochs(X, z, bad_idx):\n",
    "    \"\"\"\n",
    "    Marks bad epochs in both EEG data (X) and labels (z) by setting them to NaN (or another sentinel, ie -1).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        4D array of shape (n_trials, n_epochs, n_channels, n_timepoints).\n",
    "    z : ndarray\n",
    "        3D array of shape (n_trials, n_epochs, label_dim).\n",
    "    bad_idx : list of tuples\n",
    "        List of (trial, epoch, channel) indices indicating bad epochs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_marked : ndarray\n",
    "        Same shape as X, with bad epochs set to NaN (or a chosen sentinel).\n",
    "    z_marked : ndarray\n",
    "        Same shape as z, with bad epochs set to NaN (or a chosen sentinel).\n",
    "    \"\"\"\n",
    "    # Convert list of (trial, epoch, channel) to a set of (trial, epoch) pairs\n",
    "    bad_trial_epoch_pairs = set((trial, epoch) for trial, epoch, _ in bad_idx)\n",
    "\n",
    "    # Make copies so we don't overwrite the original arrays\n",
    "    X_marked = np.copy(X)\n",
    "    z_marked = np.copy(z).astype(np.float64)\n",
    "\n",
    "    # Mark each bad epoch in both X and z\n",
    "    for trial_idx, epoch_idx in bad_trial_epoch_pairs:\n",
    "        X_marked[trial_idx, epoch_idx, :, :] = np.nan \n",
    "        z_marked[trial_idx, epoch_idx, :]    = np.nan \n",
    "\n",
    "    return X_marked, z_marked\n",
    "\n",
    "def balance_classes(X, y, ratio_0_to_1=1.0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Sub-select X and y based on a specified ratio of 0s to 1s, keeping the original order.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "    y (numpy.ndarray): Label vector of shape (n_samples,).\n",
    "    ratio_0_to_1 (float): The desired ratio of 0s to 1s in the balanced dataset.\n",
    "\n",
    "    Returns:\n",
    "    X_balanced, y_balanced: Sub-selected feature matrix and label vector.\n",
    "    \"\"\"\n",
    "    # Step 1: Identify indices of 0s and 1s\n",
    "    indices_0 = np.where(y == 0)[0]\n",
    "    indices_1 = np.where(y == 1)[0]\n",
    "    \n",
    "    # Step 2: Calculate the number of samples to select for each class\n",
    "    num_1s = len(indices_1)\n",
    "    num_0s = min(len(indices_0), int(num_1s * ratio_0_to_1))\n",
    "    \n",
    "    # Step 3: Randomly sample the desired number of 0s and 1s\n",
    "    selected_indices_0 = np.random.choice(indices_0, num_0s, replace=False)\n",
    "    selected_indices_1 = np.random.choice(indices_1, num_1s, replace=False)\n",
    "    \n",
    "    # Step 4: Combine selected indices and sort to preserve original order\n",
    "    balanced_indices = np.sort(np.concatenate([selected_indices_0, selected_indices_1]))\n",
    "    \n",
    "    # Step 5: Sub-select X and y based on the balanced indices\n",
    "    X_balanced = X[balanced_indices]\n",
    "    y_balanced = y[balanced_indices]\n",
    "    \n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "def filter_valid_epochs(X, y, z=None, return_mask=False):\n",
    "    \"\"\"\n",
    "    Filters out epochs where either the features in X or the labels in y contain NaN values.\n",
    "    Optionally, if a z array is provided, it is filtered similarly.\n",
    "    \n",
    "    Parameters:\n",
    "        X (np.ndarray): A 2D numpy array with shape (n_epochs, n_features).\n",
    "        y (np.ndarray): A 1D numpy array with shape (n_epochs,).\n",
    "        z (np.ndarray, optional): An array that will be filtered using the same mask.\n",
    "        return_mask (bool, optional): If True, the boolean mask used for filtering is returned.\n",
    "    \n",
    "    Returns:\n",
    "        filtered_X (np.ndarray): X with only rows that have no NaN values.\n",
    "        filtered_y (np.ndarray): y with only entries corresponding to valid epochs.\n",
    "        filtered_z (np.ndarray or None): Filtered z array (if provided) or None.\n",
    "        mask (np.ndarray, optional): The boolean mask of valid epochs; only returned if return_mask=True.\n",
    "    \"\"\"\n",
    "    # Create a mask for valid labels and features\n",
    "    valid_label_mask = ~np.isnan(y)\n",
    "    valid_feature_mask = ~np.isnan(X).any(axis=1)\n",
    "    combined_mask = valid_label_mask & valid_feature_mask\n",
    "\n",
    "    # Apply the mask to X and y\n",
    "    filtered_X = X[combined_mask]\n",
    "    filtered_y = y[combined_mask]\n",
    "    \n",
    "    if z is not None:\n",
    "        filtered_z = z[combined_mask]\n",
    "    else:\n",
    "        filtered_z = None\n",
    "\n",
    "    if return_mask:\n",
    "        return filtered_X, filtered_y, filtered_z, combined_mask\n",
    "    else:\n",
    "        return filtered_X, filtered_y, filtered_z\n",
    "    \n",
    "def extract_features_from_X(X_matrix, ToI = None):\n",
    "    \"\"\"\n",
    "    Extracts the maximum amplitudes from specified time ranges for each trial, epoch, and channel in the input data.\n",
    "\n",
    "    Parameters:\n",
    "    - X_matrix: A 4D numpy array of shape (n_trials, n_epochs, n_channels, n_samples) representing the input data.\n",
    "    - ToI: A list of tuples, where each tuple contains the start and end indices of a time range of interest.\n",
    "\n",
    "    Returns:\n",
    "    - feature_matrix: A 4D numpy array of shape (n_trials, n_epochs, n_channels, len(ToI)) containing the maximum\n",
    "                      values from the specified time ranges for each trial, epoch, and channel.\n",
    "    \"\"\"\n",
    "    # Extract the shape of the input matrix\n",
    "    n_trials, n_epochs, n_channels, n_samples = X_matrix.shape \n",
    "    \n",
    "    # Initialize the feature matrix to store maximum values for each time range\n",
    "    feature_matrix = np.zeros((n_trials, n_epochs, n_channels, len(ToI)))\n",
    "\n",
    "    # Loop over the time ranges (ToI) and extract the max value for each range\n",
    "    for i_range, (start, end) in enumerate(ToI):\n",
    "        # For each time range, find the maximum values along the last axis (time samples) in the specified range\n",
    "        feature_matrix[ :, :, :, i_range] = np.mean((X_matrix[ :, :, :, start:end]), axis=-1)\n",
    "\n",
    "    # Return the feature matrix\n",
    "    return feature_matrix\n",
    "\n",
    "# Function to apply baseline correction\n",
    "def apply_baseline_correction(epochs, baseline_start_sample, baseline_end_sample):\n",
    "    baseline = np.mean(epochs[:, :, baseline_start_sample:baseline_end_sample], axis=2, keepdims=True)\n",
    "    return epochs - baseline  # Subtract baseline from all samples in the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a393274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing VPpdik...\n",
      "  Fold 1/4\n",
      "Shape of epochs_trn: (60, 80, 63, 108)\n",
      "Shape of epochs_tst: (20, 80, 63, 108)\n",
      "Shape of X_clean_trn: (60, 80, 63, 108)\n",
      "Shape of X_clean_tst: (20, 80, 63, 108)\n",
      "Shape of features_trn: (60, 80, 63, 6)\n",
      "Shape of features_tst: (20, 80, 63, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 378)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 65)\n",
      "Shape of combined_features_tst: (20, 65)\n",
      "Fold 1 Accuracy: 0.500\n",
      "  Fold 2/4\n",
      "Shape of epochs_trn: (60, 80, 63, 108)\n",
      "Shape of epochs_tst: (20, 80, 63, 108)\n",
      "Shape of X_clean_trn: (60, 80, 63, 108)\n",
      "Shape of X_clean_tst: (20, 80, 63, 108)\n",
      "Shape of features_trn: (60, 80, 63, 6)\n",
      "Shape of features_tst: (20, 80, 63, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 378)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 65)\n",
      "Shape of combined_features_tst: (20, 65)\n",
      "Fold 2 Accuracy: 0.650\n",
      "  Fold 3/4\n",
      "Shape of epochs_trn: (60, 80, 63, 108)\n",
      "Shape of epochs_tst: (20, 80, 63, 108)\n",
      "Shape of X_clean_trn: (60, 80, 63, 108)\n",
      "Shape of X_clean_tst: (20, 80, 63, 108)\n",
      "Shape of features_trn: (60, 80, 63, 6)\n",
      "Shape of features_tst: (20, 80, 63, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 378)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 65)\n",
      "Shape of combined_features_tst: (20, 65)\n",
      "Fold 3 Accuracy: 0.500\n",
      "  Fold 4/4\n",
      "Shape of epochs_trn: (60, 80, 63, 108)\n",
      "Shape of epochs_tst: (20, 80, 63, 108)\n",
      "Shape of X_clean_trn: (60, 80, 63, 108)\n",
      "Shape of X_clean_tst: (20, 80, 63, 108)\n",
      "Shape of features_trn: (60, 80, 63, 6)\n",
      "Shape of features_tst: (20, 80, 63, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 378)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 65)\n",
      "Shape of combined_features_tst: (20, 65)\n",
      "Fold 4 Accuracy: 0.550\n",
      "Average Accuracy for VPpdik: 0.550\n",
      "Processing VPpdil...\n",
      "  Fold 1/4\n",
      "Shape of epochs_trn: (60, 80, 63, 108)\n",
      "Shape of epochs_tst: (20, 80, 63, 108)\n",
      "Shape of X_clean_trn: (60, 80, 63, 108)\n",
      "Shape of X_clean_tst: (20, 80, 63, 108)\n",
      "Shape of features_trn: (60, 80, 63, 6)\n",
      "Shape of features_tst: (20, 80, 63, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 378)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 65)\n",
      "Shape of combined_features_tst: (20, 65)\n",
      "Fold 1 Accuracy: 0.850\n",
      "  Fold 2/4\n",
      "Shape of epochs_trn: (60, 80, 63, 108)\n",
      "Shape of epochs_tst: (20, 80, 63, 108)\n",
      "Shape of X_clean_trn: (60, 80, 63, 108)\n",
      "Shape of X_clean_tst: (20, 80, 63, 108)\n",
      "Shape of features_trn: (60, 80, 63, 6)\n",
      "Shape of features_tst: (20, 80, 63, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 378)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 65)\n",
      "Shape of combined_features_tst: (20, 65)\n",
      "Fold 2 Accuracy: 0.500\n",
      "  Fold 3/4\n",
      "Shape of epochs_trn: (60, 80, 63, 108)\n",
      "Shape of epochs_tst: (20, 80, 63, 108)\n",
      "Shape of X_clean_trn: (60, 80, 63, 108)\n",
      "Shape of X_clean_tst: (20, 80, 63, 108)\n",
      "Shape of features_trn: (60, 80, 63, 6)\n",
      "Shape of features_tst: (20, 80, 63, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 378)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 65)\n",
      "Shape of combined_features_tst: (20, 65)\n",
      "Fold 3 Accuracy: 1.000\n",
      "  Fold 4/4\n",
      "Shape of epochs_trn: (60, 80, 63, 108)\n",
      "Shape of epochs_tst: (20, 80, 63, 108)\n",
      "Shape of X_clean_trn: (60, 80, 63, 108)\n",
      "Shape of X_clean_tst: (20, 80, 63, 108)\n",
      "Shape of features_trn: (60, 80, 63, 6)\n",
      "Shape of features_tst: (20, 80, 63, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 378)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 65)\n",
      "Shape of combined_features_tst: (20, 65)\n",
      "Fold 4 Accuracy: 1.000\n",
      "Average Accuracy for VPpdil: 0.840\n",
      "Processing VPpdim...\n",
      "  Fold 1/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 1 Accuracy: 0.700\n",
      "  Fold 2/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 2 Accuracy: 0.500\n",
      "  Fold 3/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 3 Accuracy: 0.950\n",
      "  Fold 4/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 4 Accuracy: 0.500\n",
      "Average Accuracy for VPpdim: 0.660\n",
      "Processing VPpdin...\n",
      "  Fold 1/4\n",
      "Shape of epochs_trn: (60, 80, 62, 108)\n",
      "Shape of epochs_tst: (20, 80, 62, 108)\n",
      "Shape of X_clean_trn: (60, 80, 62, 108)\n",
      "Shape of X_clean_tst: (20, 80, 62, 108)\n",
      "Shape of features_trn: (60, 80, 62, 6)\n",
      "Shape of features_tst: (20, 80, 62, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 372)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 64)\n",
      "Shape of combined_features_tst: (20, 64)\n",
      "Fold 1 Accuracy: 0.500\n",
      "  Fold 2/4\n",
      "Shape of epochs_trn: (60, 80, 62, 108)\n",
      "Shape of epochs_tst: (20, 80, 62, 108)\n",
      "Shape of X_clean_trn: (60, 80, 62, 108)\n",
      "Shape of X_clean_tst: (20, 80, 62, 108)\n",
      "Shape of features_trn: (60, 80, 62, 6)\n",
      "Shape of features_tst: (20, 80, 62, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 372)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 64)\n",
      "Shape of combined_features_tst: (20, 64)\n",
      "Fold 2 Accuracy: 0.500\n",
      "  Fold 3/4\n",
      "Shape of epochs_trn: (60, 80, 62, 108)\n",
      "Shape of epochs_tst: (20, 80, 62, 108)\n",
      "Shape of X_clean_trn: (60, 80, 62, 108)\n",
      "Shape of X_clean_tst: (20, 80, 62, 108)\n",
      "Shape of features_trn: (60, 80, 62, 6)\n",
      "Shape of features_tst: (20, 80, 62, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 372)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 64)\n",
      "Shape of combined_features_tst: (20, 64)\n",
      "Fold 3 Accuracy: 0.700\n",
      "  Fold 4/4\n",
      "Shape of epochs_trn: (60, 80, 62, 108)\n",
      "Shape of epochs_tst: (20, 80, 62, 108)\n",
      "Shape of X_clean_trn: (60, 80, 62, 108)\n",
      "Shape of X_clean_tst: (20, 80, 62, 108)\n",
      "Shape of features_trn: (60, 80, 62, 6)\n",
      "Shape of features_tst: (20, 80, 62, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 372)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 64)\n",
      "Shape of combined_features_tst: (20, 64)\n",
      "Fold 4 Accuracy: 0.500\n",
      "Average Accuracy for VPpdin: 0.550\n",
      "Processing VPpdio...\n",
      "  Fold 1/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 1 Accuracy: 0.950\n",
      "  Fold 2/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 2 Accuracy: 0.950\n",
      "  Fold 3/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 3 Accuracy: 0.800\n",
      "  Fold 4/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
      "/var/folders/qx/1c8hj9_92533cb1kgn4q_yt80000gn/T/ipykernel_23621/2882666468.py:173: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_right, _ = pearsonr(epoch_scores, right_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 4 Accuracy: 0.750\n",
      "Average Accuracy for VPpdio: 0.860\n",
      "Processing VPpdip...\n",
      "  Fold 1/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 1 Accuracy: 0.500\n",
      "  Fold 2/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 2 Accuracy: 0.500\n",
      "  Fold 3/4\n",
      "Shape of epochs_trn: (60, 80, 64, 108)\n",
      "Shape of epochs_tst: (20, 80, 64, 108)\n",
      "Shape of X_clean_trn: (60, 80, 64, 108)\n",
      "Shape of X_clean_tst: (20, 80, 64, 108)\n",
      "Shape of features_trn: (60, 80, 64, 6)\n",
      "Shape of features_tst: (20, 80, 64, 6)\n",
      "Shape of X_trn_epochs (this is fed into LDA): (4800, 384)\n",
      "Shape of y_trn_epochs (this is fed into LDA): (4800,)\n",
      "Shape of combined_features_trn: (60, 66)\n",
      "Shape of combined_features_tst: (20, 66)\n",
      "Fold 3 Accuracy: 0.550\n",
      "  Fold 4/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 73\u001b[0m\n\u001b[1;32m     66\u001b[0m X_tst, y_tst, z_tst \u001b[38;5;241m=\u001b[39m X[folds \u001b[38;5;241m==\u001b[39m i_fold, :, :], y[folds \u001b[38;5;241m==\u001b[39m i_fold], z[folds \u001b[38;5;241m==\u001b[39m i_fold, :, :]\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# --- P300 ---\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# - Obtaining target-locked epochs - \u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Extract epochs\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m epochs_trn, bad_epochs_trn \u001b[38;5;241m=\u001b[39m \u001b[43mextract_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamplitude_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrejection_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m epochs_tst, bad_epochs_tst \u001b[38;5;241m=\u001b[39m extract_epochs(X_tst, amplitude_threshold\u001b[38;5;241m=\u001b[39mrejection_threshold)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of epochs_trn:\u001b[39m\u001b[38;5;124m\"\u001b[39m, epochs_trn\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[57], line 50\u001b[0m, in \u001b[0;36mextract_epochs\u001b[0;34m(X, start_idx, end_idx, step_size, start_sample_offset, end_sample_offset, amplitude_threshold)\u001b[0m\n\u001b[1;32m     47\u001b[0m epoch_data \u001b[38;5;241m=\u001b[39m data[epoch_start_idx:epoch_end_idx]\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Baseline correction\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m baseline_mean \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m epoch_data \u001b[38;5;241m=\u001b[39m epoch_data \u001b[38;5;241m-\u001b[39m baseline_mean\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Store the epoch in the output matrix\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:129\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    127\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret \u001b[38;5;241m/\u001b[39m rcount)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         ret \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(\u001b[43mret\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrcount\u001b[49m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     ret \u001b[38;5;241m=\u001b[39m ret \u001b[38;5;241m/\u001b[39m rcount\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "import warnings\n",
    "import mne\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.signal import welch\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "\n",
    "# Suppress all warnings\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# Directory containing the preprocessed data\n",
    "file_dir = '/Users/juliette/Desktop/thesis/preprocessing/hybrid_preprocessing'\n",
    "decoding_results_dir = '/Users/juliette/Desktop/thesis/results/alpha+p300'\n",
    "\n",
    "# Define the alpha range for PSD calculation\n",
    "min_bin = 8\n",
    "max_bin = 12\n",
    "rejection_threshold = 60e-6\n",
    "discard_threshold = 20\n",
    "\n",
    "\n",
    "# Initialize results storage\n",
    "results = []\n",
    "fold_pr_auc = []\n",
    "fold_correct_trials = []\n",
    "\n",
    "# List of subjects\n",
    "subjects = [\"VPpdia\", \"VPpdib\", \"VPpdic\", \"VPpdid\", \"VPpdie\", \"VPpdif\", \"VPpdig\", \"VPpdih\", \"VPpdii\", \"VPpdij\",\n",
    "            \"VPpdik\", \"VPpdil\", \"VPpdim\", \"VPpdin\", \"VPpdio\", \"VPpdip\", \"VPpdiq\", \"VPpdir\", \"VPpdis\", \"VPpdit\",\n",
    "            \"VPpdiu\", \"VPpdiv\", \"VPpdiw\", \"VPpdix\", \"VPpdiy\", \"VPpdiz\", \"VPpdiza\", \"VPpdizb\", \"VPpdizc\"]\n",
    "\n",
    "subjects = [\"VPpdik\", \"VPpdil\", \"VPpdim\", \"VPpdin\", \"VPpdio\", \"VPpdip\", \"VPpdiq\", \"VPpdir\", \"VPpdis\", \"VPpdit\"]\n",
    "# Load Data for each subject\n",
    "for subject in subjects:\n",
    "    print(f\"Processing {subject}...\")\n",
    "    # Load preprocessed data\n",
    "    fn = os.path.join(file_dir, f\"sub-{subject}_task-covert_c-VEP+P300_ICA.npz\")\n",
    "    tmp = np.load(fn)\n",
    "\n",
    "    X = tmp[\"X\"]  # EEG data matrix (trials, channels, samples)\n",
    "    y = tmp[\"y\"]  # Labels\n",
    "    z = tmp[\"z\"]  # Target presence (trials, epochs, sides)\n",
    "    V = tmp[\"V\"]  # One code cycle (classes, samples)\n",
    "    fs = tmp[\"fs\"].flatten()[0]\n",
    "    nyquist_freq = fs // 2\n",
    "\n",
    "    # Cross-validation\n",
    "    fold_accuracies = []\n",
    "    n_folds = 4\n",
    "    n_trials = X.shape[0] // n_folds\n",
    "    folds = np.repeat(np.arange(n_folds), n_trials)\n",
    "\n",
    "    new_feature_vectors = []\n",
    "\n",
    "    for i_fold in range(n_folds):\n",
    "        print(f\"  Fold {i_fold + 1}/{n_folds}\")\n",
    "\n",
    "        # Split train and test data\n",
    "        X_trn, y_trn, z_trn = X[folds != i_fold, :, :], y[folds != i_fold], z[folds != i_fold, :, :]\n",
    "        X_tst, y_tst, z_tst = X[folds == i_fold, :, :], y[folds == i_fold], z[folds == i_fold, :, :]\n",
    "\n",
    "        \n",
    "        # --- P300 ---\n",
    "        # - Obtaining target-locked epochs - \n",
    "        \n",
    "        # Extract epochs\n",
    "        epochs_trn, bad_epochs_trn = extract_epochs(X_trn, amplitude_threshold=rejection_threshold)\n",
    "        epochs_tst, bad_epochs_tst = extract_epochs(X_tst, amplitude_threshold=rejection_threshold)\n",
    "        print(\"Shape of epochs_trn:\", epochs_trn.shape)\n",
    "        print(\"Shape of epochs_tst:\", epochs_tst.shape)\n",
    "\n",
    "        # Mark bad epochs in both EEG data and labels\n",
    "        X_clean_trn, z_clean_trn = mark_bad_epochs(epochs_trn, z_trn, bad_epochs_trn)\n",
    "        X_clean_tst, z_clean_tst = mark_bad_epochs(epochs_tst, z_tst, bad_epochs_tst)\n",
    "        print(\"Shape of X_clean_trn:\", X_clean_trn.shape)\n",
    "        print(\"Shape of X_clean_tst:\", X_clean_tst.shape)\n",
    "        \n",
    "        # Extract features from valid epochs. Shape: (trials, epochs, channels, samples)\n",
    "        ToI = [(30, 38), (38, 48), (48, 57), (57, 69), (69, 87), (87, 108)]\n",
    "        features_trn = extract_features_from_X(X_clean_trn, ToI)\n",
    "        features_tst = extract_features_from_X(X_clean_tst, ToI)\n",
    "        print(\"Shape of features_trn:\", features_trn.shape)\n",
    "        print(\"Shape of features_tst:\", features_tst.shape)\n",
    "        \n",
    "        # - Training -\n",
    "        # Flatten training trials into epochs: shape becomes (n_trials * epochs, channel * features)\n",
    "        features_trn = features_trn.reshape(-1, features_trn.shape[2] * features_trn.shape[3])\n",
    "        \n",
    "        # Extract labels for training epochs using z and y \n",
    "        trial_indices_trn = np.arange(len(y_trn))  # indices for trials\n",
    "        y_trn_epochs = z_trn[trial_indices_trn, :, y_trn].reshape(-1)\n",
    "        \n",
    "        X_trn_epochs = np.nan_to_num(features_trn, nan=0)\n",
    "        y_trn_epochs = np.nan_to_num(y_trn_epochs, nan=0)\n",
    "        \n",
    "        print(\"Shape of X_trn_epochs (this is fed into LDA):\", X_trn_epochs.shape)\n",
    "        print(\"Shape of y_trn_epochs (this is fed into LDA):\", y_trn_epochs.shape)\n",
    "        \n",
    "        # Fit LDA\n",
    "        lda = LDA(solver=\"lsqr\", covariance_estimator=LedoitWolf())\n",
    "        lda.fit(X_trn_epochs, y_trn_epochs)  # Dimensionality bust be 2\n",
    "\n",
    "        # - Testing -\n",
    "        # Flatten testing trials into epochs\n",
    "        X_tst_epochs = features_tst.reshape(-1, features_tst.shape[2] * features_tst.shape[3])\n",
    "        \n",
    "        # Extract labels for testing epochs (again, using z and y for indexing)\n",
    "        trial_indices_tst = np.arange(len(y_tst))\n",
    "        y_tst_epochs = z_tst[trial_indices_tst, :, y_tst].reshape(-1)\n",
    "        \n",
    "        # Reshape z_tst_trials into epochs.\n",
    "        z_tst_epochs = z_tst.reshape(len(y_tst) * z_tst.shape[1], 2)\n",
    "        \n",
    "        # Filter testing epochs and also retrieve the original mask so we can count epochs per trial\n",
    "        X_tst_epochs = np.nan_to_num(X_tst_epochs, nan=0)\n",
    "        y_tst_epochs = np.nan_to_num(y_tst_epochs, nan=0)\n",
    "        \n",
    "        # Filter testing epochs and also retrieve the original mask so we can count epochs per trial\n",
    "        X_tst_epochs, y_tst_epochs, z_tst_epochs, combined_mask_tst = filter_valid_epochs(\n",
    "            X_tst_epochs, y_tst_epochs, z=z_tst_epochs, return_mask=True\n",
    "        )\n",
    "        \n",
    "        # Calculate the number of preserved epochs per trial for testing.\n",
    "        # Here, combined_mask_tst still has the original shape before filtering.\n",
    "        # Reshape it to [n_trials, epochs_per_trial] and sum True values per trial.\n",
    "        epoch_counts = combined_mask_tst.reshape(len(y_tst), -1)\n",
    "        num_epochs = np.sum(epoch_counts, axis=1)\n",
    "        \n",
    "        # Rebuild trial structure for testing data based on num_epochs\n",
    "        nested_X_tst_trials = []\n",
    "        nested_z_tst_epochs = []\n",
    "        start_idx = 0\n",
    "        for trial_idx, n_ep in enumerate(num_epochs):\n",
    "            end_idx = start_idx + n_ep\n",
    "            nested_X_tst_trials.append(X_tst_epochs[start_idx:end_idx])\n",
    "            nested_z_tst_epochs.append(z_tst_epochs[start_idx:end_idx])\n",
    "            start_idx = end_idx\n",
    "        \n",
    "\n",
    "        # Evaluate model on test data\n",
    "        correct_trials = 0\n",
    "        \n",
    "        for t_idx in range(len(y_tst)):\n",
    "\n",
    "            num_preserved_epochs = num_epochs[t_idx]\n",
    "            if num_preserved_epochs < discard_threshold:\n",
    "                discarded_trial_counter +=1\n",
    "                continue\n",
    "            \n",
    "            # Log cued side informed by y_tst\n",
    "            cued_side = y_tst[t_idx]\n",
    "            # create event vectors & ground truth\n",
    "            left_targets = nested_z_tst_epochs[t_idx][:, 0]\n",
    "            right_targets = nested_z_tst_epochs[t_idx][:, 1]\n",
    "            cued_targets = nested_z_tst_epochs[t_idx] [:, cued_side]\n",
    "   \n",
    "            # Compute LDA scores for epochs\n",
    "            epoch_scores = lda.decision_function(nested_X_tst_trials[t_idx])\n",
    "            \n",
    "            # Log performance per fold\n",
    "            precision, recall, _ = precision_recall_curve(cued_targets, epoch_scores)\n",
    "            pr_auc_score = auc(recall, precision)\n",
    "            fold_pr_auc.append(pr_auc_score)\n",
    "\n",
    "            # Correlation-based decision\n",
    "            corr_left, _ = pearsonr(epoch_scores, left_targets)\n",
    "            corr_right, _ = pearsonr(epoch_scores, right_targets)\n",
    "\n",
    "            # Trial-level decision rule based on correlation\n",
    "            decision = 0 if corr_left > corr_right else 1\n",
    "            if decision == cued_side:\n",
    "                correct_trials += 1\n",
    "\n",
    "\n",
    "        # --- Alpha Extraction ---\n",
    "\n",
    "        # Extract alpha features. For all trials, average over frequency bin (8-12 Hz) per channel using Welch's method\n",
    "        psd_features_trn = np.array([\n",
    "            welch(trial, fs=fs, nperseg=nyquist_freq, scaling='density')[1] # Set number of data points in each segment to the Nyquist frequency\n",
    "            [:, (min_bin <= freqs) & (freqs <= max_bin)].mean(axis=1) # Selects only the frequencies between min_bin and max_bin and averages over all channels\n",
    "            for trial, freqs in [(X_trn[i], welch(X_trn[i][0], fs=fs, nperseg=fs//2)[0]) \n",
    "            for i in range(X_trn.shape[0])] # For each trial, pair its EEG data with frequency bins computed from the first channel's Welch PSD) to prepare for bandpower analysis\n",
    "        ])\n",
    "        \n",
    "        psd_features_tst = np.array([\n",
    "            welch(trial, fs=fs, nperseg=nyquist_freq, scaling='density')[1] # Set number of data points in each segment to the Nyquist frequency\n",
    "            [:, (min_bin <= freqs) & (freqs <= max_bin)].mean(axis=1) # Selects only the frequencies between min_bin and max_bin and averages over all channels\n",
    "            for trial, freqs in [(X_tst[i], welch(X_tst[i][0], fs=fs, nperseg=fs//2)[0])\n",
    "            for i in range(X_tst.shape[0])] # For each trial, pair its EEG data with frequency bins computed from the first channel's Welch PSD) to prepare for bandpower analysis\n",
    "        ])\n",
    "\n",
    "\n",
    "        # --- Concatenation ---\n",
    "        # Concatenate the P300 correlation and the alpha PSD features\n",
    "        combined_features_trn = np.column_stack([corr_left * np.ones(X_trn.shape[0]),  # Left stimulus correlation\n",
    "                                                 corr_right * np.ones(X_trn.shape[0]),  # Right stimulus correlation\n",
    "                                                 psd_features_trn])  # Alpha PSD features\n",
    "\n",
    "        combined_features_tst = np.column_stack([corr_left * np.ones(X_tst.shape[0]),  # Left stimulus correlation\n",
    "                                                 corr_right * np.ones(X_tst.shape[0]),  # Right stimulus correlation\n",
    "                                                 psd_features_tst])  # Alpha PSD features\n",
    "\n",
    "        # Replace NaN values with 0\n",
    "        combined_features_trn = np.nan_to_num(combined_features_trn, nan=0)\n",
    "        combined_features_tst = np.nan_to_num(combined_features_tst, nan=0)\n",
    "\n",
    "        print(f\"Shape of combined_features_trn: {combined_features_trn.shape}\")\n",
    "        print(f\"Shape of combined_features_tst: {combined_features_tst.shape}\")\n",
    "\n",
    "        # --- Ensemble ---\n",
    "        # Train final LDA on new feature vectors (combined features)\n",
    "        lda_combine = LDA(solver=\"lsqr\", covariance_estimator=LedoitWolf())\n",
    "        lda_combine.fit(combined_features_trn, y_trn)\n",
    "\n",
    "        # Final prediction\n",
    "        y_final = lda_combine.predict(combined_features_tst)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = np.mean(y_final == y_tst)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"Fold {i_fold + 1} Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    # Compute subject-level results\n",
    "    accuracy = np.round(np.mean(fold_accuracies), 2)\n",
    "    se = np.round(np.std(fold_accuracies) / np.sqrt(n_folds), 2)\n",
    "    results.append((subject, accuracy, se))\n",
    "\n",
    "    # Print average accuracy per subject\n",
    "    print(f\"Average Accuracy for {subject}: {accuracy:.3f}\")\n",
    "\n",
    "# # Save results\n",
    "# if not os.path.exists(decoding_results_dir):\n",
    "#         os.makedirs(decoding_results_dir)\n",
    "# results_save_path = join(decoding_results_dir, f\"covert_alpha_p300_results_concat.npy\")     \n",
    "# np.save(results_save_path, results_array)    \n",
    "\n",
    "# Convert results to a structured numpy array\n",
    "results_array = np.array(\n",
    "    results, dtype=[('subject', 'U10'), ('accuracy', 'f4'), ('standard_error', 'f4')]\n",
    ")\n",
    "\n",
    "# Overall results\n",
    "overall_accuracy = np.round(results_array['accuracy'].mean(), 2)\n",
    "overall_se = np.round(results_array['standard_error'].mean(), 2)\n",
    "print(f\"Overall LDA accuracy with PSD: {overall_accuracy:.2f} ± {overall_se:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9be8eff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing VPpdik...\n",
      "  Fold 1/4\n",
      "    Fold accuracy: 0.50\n",
      "  Fold 2/4\n",
      "    Fold accuracy: 0.45\n",
      "  Fold 3/4\n",
      "    Fold accuracy: 0.60\n",
      "  Fold 4/4\n",
      "    Fold accuracy: 0.70\n",
      "VPpdik: Accuracy = 0.56, SE = 0.05\n",
      "Processing VPpdil...\n",
      "  Fold 1/4\n",
      "    Fold accuracy: 0.85\n",
      "  Fold 2/4\n",
      "    Fold accuracy: 0.95\n",
      "  Fold 3/4\n",
      "    Fold accuracy: 1.00\n",
      "  Fold 4/4\n",
      "    Fold accuracy: 1.00\n",
      "VPpdil: Accuracy = 0.95, SE = 0.03\n",
      "Processing VPpdim...\n",
      "  Fold 1/4\n",
      "    Fold accuracy: 0.85\n",
      "  Fold 2/4\n",
      "    Fold accuracy: 0.90\n",
      "  Fold 3/4\n",
      "    Fold accuracy: 0.95\n",
      "  Fold 4/4\n",
      "    Fold accuracy: 0.95\n",
      "VPpdim: Accuracy = 0.91, SE = 0.02\n",
      "Processing VPpdin...\n",
      "  Fold 1/4\n",
      "    Fold accuracy: 0.60\n",
      "  Fold 2/4\n",
      "    Fold accuracy: 0.70\n",
      "  Fold 3/4\n",
      "    Fold accuracy: 0.80\n",
      "  Fold 4/4\n",
      "    Fold accuracy: 0.75\n",
      "VPpdin: Accuracy = 0.71, SE = 0.04\n",
      "Processing VPpdio...\n",
      "  Fold 1/4\n",
      "    Fold accuracy: 0.95\n",
      "  Fold 2/4\n",
      "    Fold accuracy: 0.90\n",
      "  Fold 3/4\n",
      "    Fold accuracy: 0.85\n",
      "  Fold 4/4\n",
      "    Fold accuracy: 0.90\n",
      "VPpdio: Accuracy = 0.90, SE = 0.02\n",
      "Processing VPpdip...\n",
      "  Fold 1/4\n",
      "    Fold accuracy: 0.50\n",
      "  Fold 2/4\n",
      "    Fold accuracy: 0.65\n",
      "  Fold 3/4\n",
      "    Fold accuracy: 0.65\n",
      "  Fold 4/4\n",
      "    Fold accuracy: 0.60\n",
      "VPpdip: Accuracy = 0.60, SE = 0.03\n",
      "Processing VPpdiq...\n",
      "  Fold 1/4\n",
      "    Fold accuracy: 0.80\n",
      "  Fold 2/4\n",
      "    Fold accuracy: 0.75\n",
      "  Fold 3/4\n",
      "    Fold accuracy: 0.75\n",
      "  Fold 4/4\n",
      "    Fold accuracy: 0.80\n",
      "VPpdiq: Accuracy = 0.77, SE = 0.01\n",
      "Processing VPpdir...\n",
      "  Fold 1/4\n",
      "    Fold accuracy: 0.65\n",
      "  Fold 2/4\n",
      "    Fold accuracy: 0.70\n",
      "  Fold 3/4\n",
      "    Fold accuracy: 0.80\n",
      "  Fold 4/4\n",
      "    Fold accuracy: 0.80\n",
      "VPpdir: Accuracy = 0.74, SE = 0.03\n",
      "Processing VPpdis...\n",
      "  Fold 1/4\n",
      "    Fold accuracy: 0.90\n",
      "  Fold 2/4\n",
      "    Fold accuracy: 0.95\n",
      "  Fold 3/4\n",
      "    Fold accuracy: 0.95\n",
      "  Fold 4/4\n",
      "    Fold accuracy: 1.00\n",
      "VPpdis: Accuracy = 0.95, SE = 0.02\n",
      "Processing VPpdit...\n",
      "  Fold 1/4\n",
      "    Fold accuracy: 0.95\n",
      "  Fold 2/4\n",
      "    Fold accuracy: 1.00\n",
      "  Fold 3/4\n",
      "    Fold accuracy: 0.95\n",
      "  Fold 4/4\n",
      "    Fold accuracy: 0.95\n",
      "VPpdit: Accuracy = 0.96, SE = 0.01\n",
      "\n",
      "Average Accuracy across all subjects: 0.81\n",
      "Standard Error of Accuracy: 0.05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mne.time_frequency import psd_array_welch\n",
    "import mne\n",
    "\n",
    "# Suppress warnings from MNE\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# Define path\n",
    "file_dir = '/Users/juliette/Desktop/thesis/preprocessing/hybrid_preprocessing'\n",
    "decoding_results_dir = '/Users/juliette/Desktop/thesis/results/alpha+p300'\n",
    "\n",
    "# Set parameters\n",
    "window_size = 2     # in seconds for alpha-band sliding window\n",
    "step_size = 0.5     # sliding step\n",
    "min_bin, max_bin = 8, 13  # alpha band\n",
    "\n",
    "# Subjects\n",
    "subjects = [\"VPpdia\", \"VPpdib\", \"VPpdic\", \"VPpdid\", \"VPpdie\", \"VPpdif\", \"VPpdig\", \"VPpdih\", \"VPpdii\", \"VPpdij\",\n",
    "            \"VPpdik\", \"VPpdil\", \"VPpdim\", \"VPpdin\", \"VPpdio\", \"VPpdip\", \"VPpdiq\", \"VPpdir\", \"VPpdis\", \"VPpdit\",\n",
    "            \"VPpdiu\", \"VPpdiv\", \"VPpdiw\", \"VPpdix\", \"VPpdiy\", \"VPpdiz\", \"VPpdiza\", \"VPpdizb\", \"VPpdizc\"]\n",
    "\n",
    "subjects = [\"VPpdik\", \"VPpdil\", \"VPpdim\", \"VPpdin\", \"VPpdio\", \"VPpdip\", \"VPpdiq\", \"VPpdir\", \"VPpdis\", \"VPpdit\"]\n",
    "# Initialize results storage\n",
    "results = []\n",
    "\n",
    "# Loop over the subjects\n",
    "for subject in subjects:\n",
    "    print(f\"Processing {subject}...\")\n",
    "\n",
    "    # Load preprocessed ICA-cleaned data\n",
    "    fn = os.path.join(file_dir, f\"sub-{subject}_task-covert_c-VEP+P300_ICA.npz\")\n",
    "    tmp = np.load(fn, allow_pickle=True)\n",
    "\n",
    "    X = tmp[\"X\"]  # shape: trials × channels × samples\n",
    "    y = tmp[\"y\"]  # binary trial label (e.g., attention)\n",
    "    z = tmp[\"z\"]  # stimulus labels\n",
    "    V = tmp[\"V\"]  # marker stream, used for timing info\n",
    "    fs = int(tmp[\"fs\"].flatten()[0])\n",
    "    n_trials, n_channels, n_samples = X.shape\n",
    "\n",
    "    # Split folds\n",
    "    fold_accuracies = []\n",
    "    n_folds = 4\n",
    "    n_per_fold = n_trials // n_folds\n",
    "    folds = np.repeat(np.arange(n_folds), n_per_fold)\n",
    "\n",
    "    for i_fold in range(n_folds):\n",
    "        print(f\"  Fold {i_fold + 1}/{n_folds}\")\n",
    "\n",
    "        # Train/test split\n",
    "        X_trn, y_trn, z_trn = X[folds != i_fold], y[folds != i_fold], z[folds != i_fold]\n",
    "        X_tst, y_tst, z_tst = X[folds == i_fold], y[folds == i_fold], z[folds == i_fold]\n",
    "\n",
    "        # Frequency analysis for the alpha band\n",
    "        def extract_alpha(X_trials):\n",
    "            alpha_feats = []\n",
    "            for trial in X_trials:\n",
    "                trial_alpha = [] # This variable will hold the alpha power values for each time window in the current trial\n",
    "                total_duration = n_samples/fs\n",
    "        \n",
    "                for start in np.arange(0, total_duration - window_size, step_size):\n",
    "                    start_ix = int(start * fs) # convert the starting times to sample indices\n",
    "                    stop_ix = int(start_ix + window_size * fs)\n",
    "                    \n",
    "                    # If stop_ix exceeds the time samples in the trial the window is too large and it stops\n",
    "                    if stop_ix > trial.shape[1]:\n",
    "                        break\n",
    "                    \n",
    "                    # This contains the EEG data for the selected time window\n",
    "                    # It is sliced from the trial array for all channels, and the selected time window\n",
    "                    segment = trial[:, start_ix:stop_ix]\n",
    "                    \n",
    "                    # Adjust n_fft and use n_per_seg to avoid the error\n",
    "                    psds, freqs = psd_array_welch(\n",
    "                        segment, sfreq=fs, fmin=min_bin, fmax=max_bin, n_per_seg=segment.shape[1] # The number of points per segment \n",
    "                    )                                                                             # is equal to the length of the segment\n",
    "                    alpha_power = psds.mean(axis=1)  # average power across the frequency bins in the alpha band across channels\n",
    "                    trial_alpha.append(alpha_power)\n",
    "                trial_alpha = np.mean(trial_alpha, axis=0)  # calculate single alpha power feature for the trial\n",
    "                alpha_feats.append(trial_alpha)\n",
    "            return np.array(alpha_feats)  # shape: (trials × channels)\n",
    "\n",
    "        alpha_trn = extract_alpha(X_trn)\n",
    "        alpha_tst = extract_alpha(X_tst)\n",
    "\n",
    "\n",
    "        # --- STEP 4: ERP FEATURE EXTRACTION FOR P300 ---\n",
    "        def extract_erp_no_bins(X_trials, z_trials, y, fs, n_channels, amplitude_threshold=40e-6, start_sample_offset=-24, end_sample_offset=84, step_size=30):\n",
    "            # An empty list that will hold the ERP features for each trial\n",
    "            erp_feats = []\n",
    "\n",
    "            # Loop through each trial, stimulus coding, and attended side label\n",
    "            for trial, z, target_side in zip(X_trials, z_trials, y):\n",
    "                cued_side = target_side  # Assuming 'y' contains the trial information about which side (left or right)\n",
    "\n",
    "                # Create event vectors for left and right targets\n",
    "                left_targets = z[:, 0]  # Assuming z contains the event markers, where 0 = left, 1 = right\n",
    "                right_targets = z[:, 1]\n",
    "                attended_stimuli = z[:, cued_side]  # Select the cued target side\n",
    "\n",
    "                # Identify left and right target events\n",
    "                z_left = left_targets == 1\n",
    "                z_right = right_targets == 1\n",
    "\n",
    "                # Determine attended and unattended sides\n",
    "                if target_side == 0:  # Attending to left\n",
    "                    attended_side = z_left  # Left target is attended\n",
    "                    unattended_side = z_right  # Right target is unattended\n",
    "                else:  # Attending to right\n",
    "                    attended_side = z_right  # Right target is attended\n",
    "                    unattended_side = z_left  # Left target is unattended\n",
    "\n",
    "                # Find the indices of targets on the attended side\n",
    "                target_indices_attended = np.where(attended_side == 1)[0]\n",
    "                # Find the indices of targets on the unattended side\n",
    "                target_indices_unattended = np.where(unattended_side == 1)[0]\n",
    "\n",
    "                # If no target indices are found for both the attended and unattended sides, append a placeholder\n",
    "                if len(target_indices_attended) == 0 and len(target_indices_unattended) == 0:\n",
    "                    erp_feats.append(np.zeros(n_channels * 2))  # Placeholder (attended + unattended)\n",
    "                    continue\n",
    "\n",
    "                # Initialize arrays that will hold the ERP features for the attended and unattended targets\n",
    "                feat_attended = np.zeros(n_channels)\n",
    "                feat_unattended = np.zeros(n_channels)\n",
    "\n",
    "                # Process attended target\n",
    "                if len(target_indices_attended) > 0:\n",
    "                    # Extract the first target index, which gives the position of the attended target\n",
    "                    t_ix_attended = target_indices_attended[0]\n",
    "\n",
    "                    # Extract epochs around the attended target\n",
    "                    epoch_attended, _ = extract_epochs(trial[None, :, :], start_idx=120, end_idx=2520, step_size=30, \n",
    "                           start_sample_offset=-24, end_sample_offset=84, \n",
    "                           amplitude_threshold=40e-6)\n",
    "\n",
    "                    # Compute the ERP feature for the attended target by averaging the EEG data across the time axis\n",
    "                    feat_attended = epoch_attended.mean(axis=(1, 2))  # Averaging across epochs and channels\n",
    "\n",
    "                # Process unattended target\n",
    "                if len(target_indices_unattended) > 0:\n",
    "                    # Extract the first target index, which gives the position of the unattended target\n",
    "                    t_ix_unattended = target_indices_unattended[0]\n",
    "\n",
    "                    # Extract epochs around the unattended target\n",
    "                    epoch_unattended, _ = extract_epochs(trial[None, :, :], start_idx=120, end_idx=2520, step_size=30, \n",
    "                           start_sample_offset=-24, end_sample_offset=84, \n",
    "                           amplitude_threshold=40e-6)\n",
    "\n",
    "                    # Compute the ERP feature for the unattended target by averaging the EEG data across the time axis\n",
    "                    feat_unattended = epoch_unattended.mean(axis=(1, 2))  # Averaging across epochs and channels\n",
    "\n",
    "                # Concatenate attended and unattended features and append to the list\n",
    "                erp_feats.append(np.concatenate([feat_attended, feat_unattended]))\n",
    "\n",
    "            return np.array(erp_feats)\n",
    "\n",
    "\n",
    "        # Extract ERP features for training and testing\n",
    "        erp_trn = extract_erp_no_bins(X_trn, z_trn, y_trn, fs, n_channels)\n",
    "        erp_tst = extract_erp_no_bins(X_tst, z_tst, y_tst, fs, n_channels)\n",
    "        \n",
    "        # Flatten erp_trn and erp_tst to be 2D (trials × features)\n",
    "        erp_trn = erp_trn.reshape(erp_trn.shape[0], -1)  # Flatten to (trials × features)\n",
    "        erp_tst = erp_tst.reshape(erp_tst.shape[0], -1)  # Flatten to (trials × features)\n",
    "\n",
    "        # Now you can concatenate alpha_trn with erp_trn, and alpha_tst with erp_tst\n",
    "        F_trn = np.concatenate([alpha_trn, erp_trn], axis=1)\n",
    "        F_tst = np.concatenate([alpha_tst, erp_tst], axis=1)\n",
    "\n",
    "        # Handle NaNs, replaces any NaN values with 0\n",
    "        F_trn[np.isnan(F_trn)] = 0\n",
    "        F_tst[np.isnan(F_tst)] = 0\n",
    "\n",
    "        # Normalize, it scales the features so that they have a mean of 0 and a standard deviation of 1\n",
    "        scaler = StandardScaler()\n",
    "        F_trn = scaler.fit_transform(F_trn)\n",
    "        F_tst = scaler.transform(F_tst)\n",
    "\n",
    "        # --- STEP 6: CLASSIFICATION ---\n",
    "        clf = LDA(solver='lsqr', shrinkage='auto')  # Ledoit-Wolf shrinkage\n",
    "        clf.fit(F_trn, y_trn)\n",
    "        y_pred = clf.predict(F_tst)\n",
    "\n",
    "        acc = np.mean(y_pred == y_tst)\n",
    "        fold_accuracies.append(acc)\n",
    "        print(f\"    Fold accuracy: {acc:.2f}\")\n",
    "\n",
    "    # --- STEP 7: SAVE RESULTS FOR THIS SUBJECT ---\n",
    "    acc_mean = np.round(np.mean(fold_accuracies), 2)\n",
    "    acc_se = np.round(np.std(fold_accuracies) / np.sqrt(n_folds), 2)\n",
    "    results.append((subject, acc_mean, acc_se))\n",
    "    print(f\"{subject}: Accuracy = {acc_mean:.2f}, SE = {acc_se:.2f}\")\n",
    "\n",
    "    \n",
    "# --- STEP 8: AVERAGE ACCURACY OVER ALL SUBJECTS ---\n",
    "all_accuracies = [result[1] for result in results]\n",
    "mean_accuracy_all = np.mean(all_accuracies)\n",
    "se_accuracy_all = np.std(all_accuracies) / np.sqrt(len(all_accuracies))\n",
    "\n",
    "print(f\"\\nAverage Accuracy across all subjects: {mean_accuracy_all:.2f}\")\n",
    "print(f\"Standard Error of Accuracy: {se_accuracy_all:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f3350a5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_attended' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mX_attended\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_attended' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_attended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be87069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
